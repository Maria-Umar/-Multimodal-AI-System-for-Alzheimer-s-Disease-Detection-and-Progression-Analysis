{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5962731,"sourceType":"datasetVersion","datasetId":3419493},{"sourceId":6278618,"sourceType":"datasetVersion","datasetId":3609813}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1.1 Import Libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models, transforms\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import ImageFolder\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T16:15:51.770697Z","iopub.execute_input":"2026-01-31T16:15:51.771418Z","iopub.status.idle":"2026-01-31T16:15:51.775006Z","shell.execute_reply.started":"2026-01-31T16:15:51.771390Z","shell.execute_reply":"2026-01-31T16:15:51.774312Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# 1.2 Define Paths","metadata":{}},{"cell_type":"code","source":"MRI_DATASET_PATH = \"/kaggle/input/imagesoasis/Data\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T16:15:51.777017Z","iopub.execute_input":"2026-01-31T16:15:51.777260Z","iopub.status.idle":"2026-01-31T16:15:51.788372Z","shell.execute_reply.started":"2026-01-31T16:15:51.777240Z","shell.execute_reply":"2026-01-31T16:15:51.787634Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# 1.3 Data Transforms","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],\n                         [0.229,0.224,0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T16:15:51.789580Z","iopub.execute_input":"2026-01-31T16:15:51.789847Z","iopub.status.idle":"2026-01-31T16:15:51.801865Z","shell.execute_reply.started":"2026-01-31T16:15:51.789827Z","shell.execute_reply":"2026-01-31T16:15:51.801281Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# 1.4 Load Data","metadata":{}},{"cell_type":"code","source":"dataset = ImageFolder(MRI_DATASET_PATH, transform=transform)\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\n\ntrain_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T16:15:51.802681Z","iopub.execute_input":"2026-01-31T16:15:51.803043Z","iopub.status.idle":"2026-01-31T16:17:20.816938Z","shell.execute_reply.started":"2026-01-31T16:15:51.802999Z","shell.execute_reply":"2026-01-31T16:17:20.816257Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# 1.5 Load ResNet-50","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel_mri = models.resnet50(pretrained=True)\nmodel_mri.fc = nn.Linear(model_mri.fc.in_features, 4)\nmodel_mri = model_mri.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T16:17:20.818401Z","iopub.execute_input":"2026-01-31T16:17:20.818633Z","iopub.status.idle":"2026-01-31T16:17:21.421855Z","shell.execute_reply.started":"2026-01-31T16:17:20.818612Z","shell.execute_reply":"2026-01-31T16:17:21.421288Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"print(\"Total images:\", len(dataset))\nprint(\"Train size:\", len(train_ds))\nprint(\"Batches:\", len(train_loader))\nprint(\"Classes:\", dataset.classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T16:17:21.422768Z","iopub.execute_input":"2026-01-31T16:17:21.422992Z","iopub.status.idle":"2026-01-31T16:17:21.427158Z","shell.execute_reply.started":"2026-01-31T16:17:21.422971Z","shell.execute_reply":"2026-01-31T16:17:21.426489Z"}},"outputs":[{"name":"stdout","text":"Total images: 86437\nTrain size: 69149\nBatches: 2161\nClasses: ['Mild Dementia', 'Moderate Dementia', 'Non Demented', 'Very mild Dementia']\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntransform = transforms.Compose([\n    transforms.Resize((160,160)),   # faster\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],\n                         [0.229,0.224,0.225])\n])\n\ndataset = ImageFolder(MRI_DATASET_PATH, transform=transform)\n\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\n\ntrain_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_ds, batch_size=32, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T16:17:21.428000Z","iopub.execute_input":"2026-01-31T16:17:21.428275Z","iopub.status.idle":"2026-01-31T16:18:08.644888Z","shell.execute_reply.started":"2026-01-31T16:17:21.428244Z","shell.execute_reply":"2026-01-31T16:18:08.644092Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"# 1.6 Train MRI Model","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model_mri.parameters(), lr=1e-4)\n\nfor epoch in range(5):\n    model_mri.train()\n    running_loss = 0\n\n    for x, y in train_loader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n\n        outputs = model_mri(x)\n        loss = criterion(outputs, y)\n\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    print(f\"Epoch [{epoch+1}/5], Loss: {running_loss/len(train_loader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T16:18:08.646000Z","iopub.execute_input":"2026-01-31T16:18:08.646305Z","iopub.status.idle":"2026-01-31T16:37:55.788003Z","shell.execute_reply.started":"2026-01-31T16:18:08.646273Z","shell.execute_reply":"2026-01-31T16:37:55.787114Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/5], Loss: 0.0973\nEpoch [2/5], Loss: 0.0216\nEpoch [3/5], Loss: 0.0142\nEpoch [4/5], Loss: 0.0082\nEpoch [5/5], Loss: 0.0101\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# Accuracy","metadata":{}},{"cell_type":"code","source":"def accuracy(model, loader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            outputs = model(x)\n            _, predicted = torch.max(outputs, 1)\n            correct += (predicted == y).sum().item()\n            total += y.size(0)\n    return correct / total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T16:37:55.789517Z","iopub.execute_input":"2026-01-31T16:37:55.789823Z","iopub.status.idle":"2026-01-31T16:37:55.795177Z","shell.execute_reply.started":"2026-01-31T16:37:55.789791Z","shell.execute_reply":"2026-01-31T16:37:55.794504Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Testing Epochs","metadata":{}},{"cell_type":"code","source":"for epoch in range(5):\n    model_mri.train()\n    running_loss = 0\n\n    for x, y in train_loader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        outputs = model_mri(x)\n        loss = criterion(outputs, y)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n\n    # Compute validation accuracy\n    val_acc = accuracy(model_mri, val_loader)\n\n    print(f\"Epoch [{epoch+1}/5], Loss: {running_loss/len(train_loader):.4f}, Val Accuracy: {val_acc*100:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T16:37:55.797322Z","iopub.execute_input":"2026-01-31T16:37:55.797951Z","iopub.status.idle":"2026-01-31T17:00:37.346812Z","shell.execute_reply.started":"2026-01-31T16:37:55.797914Z","shell.execute_reply":"2026-01-31T17:00:37.345797Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/5], Loss: 0.0074, Val Accuracy: 99.95%\nEpoch [2/5], Loss: 0.0056, Val Accuracy: 100.00%\nEpoch [3/5], Loss: 0.0059, Val Accuracy: 99.98%\nEpoch [4/5], Loss: 0.0047, Val Accuracy: 99.84%\nEpoch [5/5], Loss: 0.0048, Val Accuracy: 100.00%\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# Confusion Matrix (Validation Set)","metadata":{}},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\nmodel_mri.eval()\n\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for x, y in val_loader:\n        x, y = x.to(device), y.to(device)\n        outputs = model_mri(x)\n        preds = torch.argmax(outputs, dim=1)\n\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(y.cpu().numpy())\n\ncm = confusion_matrix(all_labels, all_preds)\n\ndisp = ConfusionMatrixDisplay(\n    confusion_matrix=cm,\n    display_labels=mri_dataset.classes  # your class names\n)\n\ndisp.plot(cmap=\"Blues\", values_format=\"d\")\nplt.title(\"Confusion Matrix (MRI Model)\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Classification Report","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(\"Classification Report (MRI Model)\")\nprint(\n    classification_report(\n        all_labels,\n        all_preds,\n        target_names=mri_dataset.classes\n    )\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1.7 Save MRI Model","metadata":{}},{"cell_type":"code","source":"torch.save(model_mri.state_dict(), \"mri_resnet50.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T17:00:37.372777Z","iopub.execute_input":"2026-01-31T17:00:37.373088Z","iopub.status.idle":"2026-01-31T17:00:37.513183Z","shell.execute_reply.started":"2026-01-31T17:00:37.373058Z","shell.execute_reply":"2026-01-31T17:00:37.512392Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"## HANDWRITING MODEL","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T17:00:37.514251Z","iopub.execute_input":"2026-01-31T17:00:37.514871Z","iopub.status.idle":"2026-01-31T17:00:37.518049Z","shell.execute_reply.started":"2026-01-31T17:00:37.514847Z","shell.execute_reply":"2026-01-31T17:00:37.517405Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"# 2.1 Load Dataset","metadata":{}},{"cell_type":"code","source":"# Load CSV\ndf = pd.read_csv(\"/kaggle/input/handwriting-data-to-detect-alzheimers-disease/data.csv\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T17:00:37.519468Z","iopub.execute_input":"2026-01-31T17:00:37.519885Z","iopub.status.idle":"2026-01-31T17:00:37.635592Z","shell.execute_reply.started":"2026-01-31T17:00:37.519863Z","shell.execute_reply":"2026-01-31T17:00:37.634843Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Load CSV\ndf = pd.read_csv(\"/kaggle/input/handwriting-data-to-detect-alzheimers-disease/data.csv\")\n\n# Check first rows\nprint(df.head())\n\n# Since no label exists, create dummy labels for testing\n# 0 = Healthy, 1 = Alzheimer\n# For real use, replace this with actual labels if available\nnp.random.seed(42)\ndf['label'] = np.random.randint(0, 2, size=len(df))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T17:00:37.636669Z","iopub.execute_input":"2026-01-31T17:00:37.637058Z","iopub.status.idle":"2026-01-31T17:00:37.683104Z","shell.execute_reply.started":"2026-01-31T17:00:37.637008Z","shell.execute_reply":"2026-01-31T17:00:37.682424Z"}},"outputs":[{"name":"stdout","text":"     ID  air_time1  disp_index1  gmrt_in_air1  gmrt_on_paper1  \\\n0  id_1       5160     0.000013    120.804174       86.853334   \n1  id_2      51980     0.000016    115.318238       83.448681   \n2  id_3       2600     0.000010    229.933997      172.761858   \n3  id_4       2130     0.000010    369.403342      183.193104   \n4  id_5       2310     0.000007    257.997131      111.275889   \n\n   max_x_extension1  max_y_extension1  mean_acc_in_air1  mean_acc_on_paper1  \\\n0               957              6601          0.361800            0.217459   \n1              1694              6998          0.272513            0.144880   \n2              2333              5802          0.387020            0.181342   \n3              1756              8159          0.556879            0.164502   \n4               987              4732          0.266077            0.145104   \n\n   mean_gmrt1  ...  mean_jerk_in_air25  mean_jerk_on_paper25  \\\n0  103.828754  ...            0.141434              0.024471   \n1   99.383459  ...            0.049663              0.018368   \n2  201.347928  ...            0.178194              0.017174   \n3  276.298223  ...            0.113905              0.019860   \n4  184.636510  ...            0.121782              0.020872   \n\n   mean_speed_in_air25  mean_speed_on_paper25  num_of_pendown25  paper_time25  \\\n0             5.596487               3.184589                71         40120   \n1             1.665973               0.950249               129        126700   \n2             4.000781               2.392521                74         45480   \n3             4.206746               1.613522               123         67945   \n4             3.319036               1.680629                92         37285   \n\n   pressure_mean25  pressure_var25  total_time25  class  \n0      1749.278166     296102.7676        144605      P  \n1      1504.768272     278744.2850        298640      P  \n2      1431.443492     144411.7055         79025      P  \n3      1465.843329     230184.7154        181220      P  \n4      1841.702561     158290.0255         72575      P  \n\n[5 rows x 452 columns]\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Features: all numeric columns except ID\nX = df.drop(columns=['ID','label'])\n\n# Convert to numeric in case any column is object\nX = X.apply(pd.to_numeric, errors='coerce')\n\n# Fill missing values if any\nX = X.fillna(0).values\n\n# Labels\ny = df['label'].values.astype(int)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T17:00:37.683966Z","iopub.execute_input":"2026-01-31T17:00:37.684237Z","iopub.status.idle":"2026-01-31T17:00:37.726224Z","shell.execute_reply.started":"2026-01-31T17:00:37.684214Z","shell.execute_reply":"2026-01-31T17:00:37.725513Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"# 2.2 Pytorch Dataset","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass HandwritingFeaturesDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.tensor(X, dtype=torch.float32)\n        self.y = torch.tensor(y, dtype=torch.long)\n    def __len__(self):\n        return len(self.y)\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\ndataset = HandwritingFeaturesDataset(X, y)\n\n# Train/Validation split\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_ds, val_ds = torch.utils.data.random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=16)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T17:00:37.727039Z","iopub.execute_input":"2026-01-31T17:00:37.727253Z","iopub.status.idle":"2026-01-31T17:00:37.745901Z","shell.execute_reply.started":"2026-01-31T17:00:37.727232Z","shell.execute_reply":"2026-01-31T17:00:37.745148Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"# 2.3 Define MLP Model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\nclass HandwritingMLP(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.fc = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(),\n            nn.Linear(64, 2)  # 2 classes: Healthy / Alzheimer\n        )\n    def forward(self, x):\n        return self.fc(x)\n\nmodel_hw = HandwritingMLP(X.shape[1])\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel_hw = model_hw.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model_hw.parameters(), lr=1e-4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T17:00:37.746728Z","iopub.execute_input":"2026-01-31T17:00:37.746948Z","iopub.status.idle":"2026-01-31T17:00:37.754753Z","shell.execute_reply.started":"2026-01-31T17:00:37.746928Z","shell.execute_reply":"2026-01-31T17:00:37.754216Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"num_epochs = 10\n\nfor epoch in range(num_epochs):\n    model_hw.train()\n    total_loss = 0\n    total_correct = 0\n    \n    for x, y in train_loader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        outputs = model_hw(x)\n        loss = criterion(outputs, y)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        preds = torch.argmax(outputs, dim=1)\n        total_correct += torch.sum(preds == y).item()\n    \n    acc = total_correct / len(train_ds)\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_loader):.4f}, Accuracy: {acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T17:00:37.755518Z","iopub.execute_input":"2026-01-31T17:00:37.755742Z","iopub.status.idle":"2026-01-31T17:00:37.927546Z","shell.execute_reply.started":"2026-01-31T17:00:37.755721Z","shell.execute_reply":"2026-01-31T17:00:37.927004Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10, Loss: 1523.3980, Accuracy: 0.4748\nEpoch 2/10, Loss: 842.3512, Accuracy: 0.5108\nEpoch 3/10, Loss: 635.2526, Accuracy: 0.5468\nEpoch 4/10, Loss: 604.4701, Accuracy: 0.5899\nEpoch 5/10, Loss: 380.6199, Accuracy: 0.5827\nEpoch 6/10, Loss: 400.3154, Accuracy: 0.5468\nEpoch 7/10, Loss: 277.7246, Accuracy: 0.6619\nEpoch 8/10, Loss: 224.1495, Accuracy: 0.6259\nEpoch 9/10, Loss: 277.7512, Accuracy: 0.7050\nEpoch 10/10, Loss: 169.0568, Accuracy: 0.7050\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"# Confusion Matrix (Handwriting Model)","metadata":{}},{"cell_type":"code","source":"import torch\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\nmodel_hw.eval()\n\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():\n    for x, y in val_loader:   # use validation or test loader\n        x, y = x.to(device), y.to(device)\n        outputs = model_hw(x)\n        preds = torch.argmax(outputs, dim=1)\n\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(y.cpu().numpy())\n\ncm = confusion_matrix(all_labels, all_preds)\n\ndisp = ConfusionMatrixDisplay(\n    confusion_matrix=cm,\n    display_labels=range(len(set(all_labels)))  # or class names if available\n)\n\ndisp.plot(cmap=\"Blues\", values_format=\"d\")\nplt.title(\"Confusion Matrix (Handwriting Model)\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Classification Report (Handwriting Model)","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(\"Classification Report (Handwriting Model)\")\nprint(\n    classification_report(\n        all_labels,\n        all_preds\n    )\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2.4 Save Model","metadata":{}},{"cell_type":"code","source":"torch.save(model_hw.state_dict(), \"handwriting_mlp_model.pth\")\nprint(\"Handwriting MLP model saved successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T17:00:37.928378Z","iopub.execute_input":"2026-01-31T17:00:37.928673Z","iopub.status.idle":"2026-01-31T17:00:37.934264Z","shell.execute_reply.started":"2026-01-31T17:00:37.928632Z","shell.execute_reply":"2026-01-31T17:00:37.933583Z"}},"outputs":[{"name":"stdout","text":"Handwriting MLP model saved successfully!\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import torch\nimport torchvision.models as models\nimport torch.nn as nn\n\n# Load pretrained ResNet50\nresnet50 = models.resnet50(pretrained=True)\n\n# Replace final layer to match your classes (4 Alzheimer stages)\nnum_classes = 4\nresnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nresnet50 = resnet50.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T17:00:37.935068Z","iopub.execute_input":"2026-01-31T17:00:37.935321Z","iopub.status.idle":"2026-01-31T17:00:38.416599Z","shell.execute_reply.started":"2026-01-31T17:00:37.935301Z","shell.execute_reply":"2026-01-31T17:00:38.415860Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nimport torchvision\nfrom torchvision import datasets, transforms, models\nimport torch.nn as nn\nimport torch.optim as optim\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T17:00:38.417514Z","iopub.execute_input":"2026-01-31T17:00:38.417729Z","iopub.status.idle":"2026-01-31T17:00:38.421488Z","shell.execute_reply.started":"2026-01-31T17:00:38.417708Z","shell.execute_reply":"2026-01-31T17:00:38.420946Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\nMRI_PATH = \"/kaggle/input/imagesoasis/Data\" # replace with actual path\n\nmri_dataset = datasets.ImageFolder(MRI_PATH, transform=transform)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T17:00:38.422338Z","iopub.execute_input":"2026-01-31T17:00:38.422552Z","iopub.status.idle":"2026-01-31T17:00:58.953005Z","shell.execute_reply.started":"2026-01-31T17:00:38.422533Z","shell.execute_reply":"2026-01-31T17:00:58.952442Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Image transforms\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # ResNet requires 224x224\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],  # ImageNet mean\n                         [0.229, 0.224, 0.225])  # ImageNet std\n])\n\n# Path to your MRI images in Kaggle input\nMRI_PATH = \"/kaggle/input/imagesoasis/Data\"  # replace with your path\n\n# Assuming folder structure: \n# /MRI_PATH/class_name/image.jpg\nmri_dataset = datasets.ImageFolder(MRI_PATH, transform=transform)\n\n# Split train/val\ntrain_size = int(0.8 * len(mri_dataset))\nval_size = len(mri_dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(mri_dataset, [train_size, val_size])\n\n# DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T17:00:58.956877Z","iopub.execute_input":"2026-01-31T17:00:58.957135Z","iopub.status.idle":"2026-01-31T17:01:02.992415Z","shell.execute_reply.started":"2026-01-31T17:00:58.957113Z","shell.execute_reply":"2026-01-31T17:01:02.991637Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"# Load pretrained ResNet-50","metadata":{}},{"cell_type":"code","source":"# Load pretrained ResNet-50\nresnet50 = models.resnet50(pretrained=True)\n\n# Change the final fully connected layer to match your number of classes\nnum_classes = len(mri_dataset.classes)  # automatically get number of classes from folder names\nresnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)\n\n# Move to GPU if available\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nresnet50 = resnet50.to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(resnet50.parameters(), lr=1e-4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T17:01:02.993334Z","iopub.execute_input":"2026-01-31T17:01:02.993648Z","iopub.status.idle":"2026-01-31T17:01:03.370611Z","shell.execute_reply.started":"2026-01-31T17:01:02.993603Z","shell.execute_reply":"2026-01-31T17:01:03.370059Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"# Train the ResNet-50 model","metadata":{}},{"cell_type":"code","source":"num_epochs = 5  # you can increase to 10-20 for better performance\n\nfor epoch in range(num_epochs):\n    resnet50.train()\n    total_loss = 0\n    total_correct = 0\n    \n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = resnet50(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        preds = torch.argmax(outputs, dim=1)\n        total_correct += torch.sum(preds == labels).item()\n    \n    train_acc = total_correct / len(train_loader.dataset)\n    avg_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch+1}/{num_epochs} — Loss: {avg_loss:.4f}, Accuracy: {train_acc:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-31T17:01:03.371809Z","iopub.execute_input":"2026-01-31T17:01:03.372059Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Validate The Model ","metadata":{}},{"cell_type":"code","source":"resnet50.eval()\ntotal_correct = 0\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = resnet50(images)\n        preds = torch.argmax(outputs, dim=1)\n        total_correct += torch.sum(preds == labels).item()\n\nval_acc = total_correct / len(val_loader.dataset)\nprint(f\"Validation Accuracy: {val_acc:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save The Trained Model","metadata":{}},{"cell_type":"code","source":"torch.save(resnet50.state_dict(), \"resnet50_mri.pth\")\nprint(\"ResNet-50 MRI model saved successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 3: Extract MRI Embeddings\n\nWe remove the final fully connected layer from the trained ResNet-50\nso we can use the feature vectors (embeddings) from each MRI.\nThese embeddings will later be concatenated with handwriting embeddings\nfor the fusion network.\n","metadata":{}},{"cell_type":"markdown","source":"## Extract MRI embeddings","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\n# Remove final classification layer\nresnet_features = nn.Sequential(*list(resnet50.children())[:-1])\nresnet_features = resnet_features.to(device)\nresnet_features.eval()\n\n# Function to extract embeddings\ndef extract_mri_embeddings(dataloader):\n    embeddings = []\n    labels = []\n    with torch.no_grad():\n        for images, lbls in dataloader:\n            images = images.to(device)\n            emb = resnet_features(images)  # shape [batch, 2048, 1, 1]\n            emb = emb.view(emb.size(0), -1)  # flatten to [batch, 2048]\n            embeddings.append(emb.cpu())\n            labels.append(lbls)\n    embeddings = torch.cat(embeddings, dim=0)\n    labels = torch.cat(labels, dim=0)\n    return embeddings, labels\n\ntrain_mri_emb, train_mri_lbl = extract_mri_embeddings(train_loader)\nval_mri_emb, val_mri_lbl = extract_mri_embeddings(val_loader)\n\nprint(\"MRI Embeddings shape:\", train_mri_emb.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 3b: Extract Handwriting Embeddings\n\nWe take the last hidden layer of the trained Handwriting MLP\nas the embedding for each patient. These will be fused\nwith the MRI embeddings for multimodal prediction.\n","metadata":{}},{"cell_type":"markdown","source":"# Extract handwriting embeddings","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nimport torch\n\n# Load CSV\ndf = pd.read_csv(\"/kaggle/input/handwriting-data-to-detect-alzheimers-disease/data.csv\")\n\n# Drop ID column\ndf_numeric = df.drop(columns=[\"ID\"])\n\n# Check all columns are numeric\nprint(df_numeric.dtypes)\n\n# Convert to numeric just in case\ndf_numeric = df_numeric.apply(pd.to_numeric, errors='coerce')\n\n# Fill any missing values\ndf_numeric = df_numeric.fillna(0)\n\n# Features X\nX = df_numeric.values\n\n# Labels: for now, dummy labels (replace with real if available)\ny = torch.zeros(X.shape[0], dtype=torch.long)  # all zeros (healthy)\n# If you have a column 'label':\n# y = df['label'].values\n\n# Train/val split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Standardize numeric features\nscaler = StandardScaler()\nX_scaled_train = scaler.fit_transform(X_train)\nX_scaled_val = scaler.transform(X_val)\n\n# Convert to torch tensors\nX_scaled_train = torch.tensor(X_scaled_train, dtype=torch.float32)\nX_scaled_val = torch.tensor(X_scaled_val, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\ny_val = torch.tensor(y_val, dtype=torch.long)\n\nprint(\"Handwriting train shape:\", X_scaled_train.shape)\nprint(\"Handwriting val shape:\", X_scaled_val.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn\n\nclass HandwritingMLP(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, 128)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Linear(128, 64)  # this will be the embedding\n        self.relu2 = nn.ReLU()\n        self.fc3 = nn.Linear(64, 2)    # output layer (binary classification)\n\n    def forward(self, x, return_embedding=False):\n        x = self.relu1(self.fc1(x))\n        emb = self.relu2(self.fc2(x))  # embeddings\n        out = self.fc3(emb)\n        if return_embedding:\n            return emb\n        else:\n            return out\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"input_dim = X_scaled_train.shape[1]  # number of features\nmodel_hw = HandwritingMLP(input_dim)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel_hw = model_hw.to(device)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_hw_emb = model_hw(X_scaled_train.to(device), return_embedding=True)\nval_hw_emb = model_hw(X_scaled_val.to(device), return_embedding=True)\n\nprint(\"Handwriting embeddings shape:\", train_hw_emb.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn\n\n# Remove final fc layer to get embeddings\nresnet_features = nn.Sequential(*list(resnet50.children())[:-1]).to(device)\nresnet_features.eval()\n\ndef extract_mri_embeddings(dataloader):\n    embeddings, labels = [], []\n    with torch.no_grad():\n        for imgs, lbls in dataloader:\n            imgs = imgs.to(device)\n            emb = resnet_features(imgs)  # [batch, 2048,1,1]\n            emb = emb.view(emb.size(0), -1)  # flatten\n            embeddings.append(emb.cpu())\n            labels.append(lbls)\n    return torch.cat(embeddings, dim=0), torch.cat(labels, dim=0)\n\ntrain_mri_emb, train_mri_lbl = extract_mri_embeddings(train_loader)\nval_mri_emb, val_mri_lbl = extract_mri_embeddings(val_loader)\nprint(\"Train MRI embeddings:\", train_mri_emb.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_hw_emb = model_hw(X_scaled_train.to(device), return_embedding=True).cpu()\nval_hw_emb = model_hw(X_scaled_val.to(device), return_embedding=True).cpu()\nprint(\"Train Handwriting embeddings:\", train_hw_emb.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Create Fusion Data Loaders","metadata":{}},{"cell_type":"code","source":"from torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225])\n])\n\nMRI_PATH = \"/kaggle/input/imagesoasis/Data\"  # path to MRI images\n\n# Use ImageFolder\nmri_dataset = datasets.ImageFolder(MRI_PATH, transform=transform)\n\n# Split train/val\ntrain_size = int(0.8 * len(mri_dataset))\nval_size = len(mri_dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(mri_dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=False)  # shuffle=False to keep order\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nslice_patient_ids = [os.path.basename(os.path.dirname(path)) for path, _ in mri_dataset.imgs]\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import defaultdict\nimport torch\n\n# Assume resnet_features is your trained ResNet50 feature extractor\nresnet_features.eval()\n\npatient_emb_dict = defaultdict(list)\npatient_label_dict = {}\n\nwith torch.no_grad():\n    for idx, (img, lbl) in enumerate(mri_dataset):\n        img = img.unsqueeze(0).to(device)  # add batch dim\n        emb = resnet_features(img).view(1, -1).cpu()  # flatten\n        patient_id = slice_patient_ids[idx]\n        patient_emb_dict[patient_id].append(emb)\n        patient_label_dict[patient_id] = lbl  # same for all slices\n\n# Average embeddings per patient\ntrain_mri_patient_emb = []\ntrain_mri_patient_lbl = []\n\nfor patient_id in patient_emb_dict:\n    emb = torch.cat(patient_emb_dict[patient_id], dim=0).mean(dim=0)\n    train_mri_patient_emb.append(emb)\n    train_mri_patient_lbl.append(patient_label_dict[patient_id])\n\ntrain_mri_patient_emb = torch.stack(train_mri_patient_emb)\ntrain_mri_patient_lbl = torch.tensor(train_mri_patient_lbl)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 4: Fusion Network\n\nWe now concatenate MRI embeddings and handwriting embeddings for each patient.\nThe fused vector is input to a small MLP for final prediction.\n","metadata":{}},{"cell_type":"markdown","source":"## Fusion Network Definition","metadata":{}},{"cell_type":"code","source":"import torch\nfrom collections import defaultdict\nimport os\n\n# ResNet feature extractor (remove last fc layer)\nresnet_features = torch.nn.Sequential(*list(resnet50.children())[:-1]).to(device)\nresnet_features.eval()\n\n# Extract patient IDs from dataset paths (assuming ImageFolder structure)\nslice_patient_ids = [os.path.basename(os.path.dirname(path)) for path, _ in mri_dataset.imgs]\n\n# Store embeddings per patient\npatient_emb_dict = defaultdict(list)\npatient_label_dict = {}\n\nwith torch.no_grad():\n    for idx, (img, lbl) in enumerate(mri_dataset):\n        img = img.unsqueeze(0).to(device)\n        emb = resnet_features(img).view(1, -1).cpu()\n        patient_id = slice_patient_ids[idx]\n        patient_emb_dict[patient_id].append(emb)\n        patient_label_dict[patient_id] = lbl  # all slices same label\n\n# Average embeddings per patient\nmri_patient_emb = []\nmri_patient_lbl = []\n\nfor patient_id in patient_emb_dict:\n    emb = torch.cat(patient_emb_dict[patient_id], dim=0).mean(dim=0)\n    mri_patient_emb.append(emb)\n    mri_patient_lbl.append(patient_label_dict[patient_id])\n\nmri_patient_emb = torch.stack(mri_patient_emb)\nmri_patient_lbl = torch.tensor(mri_patient_lbl)\n\nprint(\"MRI patient-level embeddings:\", mri_patient_emb.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prepare Handwriting embeddings","metadata":{}},{"cell_type":"code","source":"# Assuming you already trained Handwriting MLP and have X_scaled_train/X_scaled_val\n# Extract embeddings from trained handwriting model\nhw_embeddings = model_hw(X_scaled_train.to(device), return_embedding=True).cpu()\nhw_labels = torch.tensor(y_train)  # make sure labels match patients\n\nprint(\"Handwriting embeddings:\", hw_embeddings.shape)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Alzheimer’s Detection – Multi-Modal (Separate Pipelines)\n\nThis notebook evaluates:\n1. MRI-based Alzheimer’s detection using ResNet-50\n2. Handwriting-based Alzheimer’s detection using tabular features\n\nDatasets are from different cohorts, so models are evaluated independently.\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load pretrained ResNet-50\nresnet50 = models.resnet50(pretrained=True)\n\n# Replace final layer with your number of classes\nnum_classes = len(mri_dataset.classes)  # e.g. 4 classes\nresnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)\n\nresnet50 = resnet50.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"resnet50.load_state_dict(torch.load(\"/kaggle/working/resnet50_mri.pth\"))\nresnet50.eval()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# MRI Evaluation (Confusion Matrix + Report)","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nimport torch\n\nresnet50.eval()\n\nall_preds, all_labels = [], []\n\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = resnet50(images)\n        preds = torch.argmax(outputs, dim=1)\n\n        all_preds.append(preds.cpu())\n        all_labels.append(labels.cpu())\n\nall_preds = torch.cat(all_preds)\nall_labels = torch.cat(all_labels)\n\n# Confusion Matrix\ncm = confusion_matrix(all_labels, all_preds)\ndisp = ConfusionMatrixDisplay(cm, display_labels=mri_dataset.classes)\ndisp.plot(cmap=\"Blues\")\nplt.title(\"MRI – Confusion Matrix\")\nplt.show()\n\n# Classification Report\nprint(\"MRI Classification Report\")\nprint(classification_report(all_labels, all_preds, target_names=mri_dataset.classes))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Select same 4 patients manually\nhw_emb_4 = hw_embeddings[selected_indices]   # shape [4, 64]\n\nfusion_input = torch.cat([mri_patient_emb, hw_emb_4], dim=1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}